{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl \n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from pytorch_lightning.metrics.functional import accuracy"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "        self.data_path = conf.data_path\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        self.dims = conf.dims \n",
    "        self.num_classes = conf.num_classes\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_path, train=True, download=True)\n",
    "        MNIST(self.data_path, train=False, download=True)\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_path, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_path, train=False, transform=self.transform)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=32)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=32)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(pl.LightningModule):\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conf = conf \n",
    "        channels, width, height = conf.dims\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels*width*height, conf.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(conf.hidden_size, conf.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(conf.hidden_size, conf.num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "    \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.conf.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'data_path': 'data/',\n",
       " 'dims': (1, 28, 28),\n",
       " 'num_classes': 10,\n",
       " 'hidden_size': 64,\n",
       " 'learning_rate': 0.0002}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "conf = Config(\n",
    "    data_path=r'data/',\n",
    "    dims=(1, 28, 28),\n",
    "    num_classes=10,\n",
    "    hidden_size=64,\n",
    "    learning_rate=2e-4,\n",
    ")\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "dm = MNISTDataModule(conf)\n",
    "model = LitMNIST(conf)\n",
    "trainer = pl.Trainer(max_epochs=3, progress_bar_refresh_rate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 55 K  \n",
      "Epoch 0:  91%|█████████ | 1700/1876 [00:11<00:01, 148.95it/s, loss=0.277, v_num=10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 1720/1876 [00:11<00:01, 147.80it/s, loss=0.277, v_num=10]\n",
      "Epoch 0:  93%|█████████▎| 1740/1876 [00:11<00:00, 148.15it/s, loss=0.277, v_num=10]\n",
      "Epoch 0:  94%|█████████▍| 1760/1876 [00:11<00:00, 148.44it/s, loss=0.277, v_num=10]\n",
      "Epoch 0:  95%|█████████▍| 1780/1876 [00:11<00:00, 148.77it/s, loss=0.277, v_num=10]\n",
      "Epoch 0:  96%|█████████▌| 1800/1876 [00:12<00:00, 149.17it/s, loss=0.277, v_num=10]\n",
      "Epoch 0:  97%|█████████▋| 1820/1876 [00:12<00:00, 149.57it/s, loss=0.277, v_num=10]\n",
      "Epoch 0:  98%|█████████▊| 1840/1876 [00:12<00:00, 148.65it/s, loss=0.365, v_num=10, val_loss=0.26, val_acc=0.923]\n",
      "Epoch 1:  91%|█████████ | 1700/1876 [00:10<00:01, 155.88it/s, loss=0.214, v_num=10, val_loss=0.26, val_acc=0.923]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 1720/1876 [00:11<00:01, 154.74it/s, loss=0.214, v_num=10, val_loss=0.26, val_acc=0.923]\n",
      "Epoch 1:  94%|█████████▍| 1760/1876 [00:11<00:00, 155.69it/s, loss=0.214, v_num=10, val_loss=0.26, val_acc=0.923]\n",
      "Validating:  51%|█████     | 80/157 [00:00<00:00, 199.96it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 1800/1876 [00:11<00:00, 156.38it/s, loss=0.214, v_num=10, val_loss=0.26, val_acc=0.923]\n",
      "Epoch 1:  98%|█████████▊| 1840/1876 [00:11<00:00, 156.05it/s, loss=0.243, v_num=10, val_loss=0.195, val_acc=0.942]\n",
      "Epoch 2:  91%|█████████ | 1700/1876 [00:10<00:01, 160.04it/s, loss=0.165, v_num=10, val_loss=0.195, val_acc=0.942]\n",
      "Epoch 2:  92%|█████████▏| 1720/1876 [00:10<00:00, 158.70it/s, loss=0.165, v_num=10, val_loss=0.195, val_acc=0.942]\n",
      "Epoch 2:  94%|█████████▍| 1760/1876 [00:11<00:00, 159.55it/s, loss=0.165, v_num=10, val_loss=0.195, val_acc=0.942]\n",
      "Epoch 2:  96%|█████████▌| 1800/1876 [00:11<00:00, 160.36it/s, loss=0.165, v_num=10, val_loss=0.195, val_acc=0.942]\n",
      "Validating:  76%|███████▋  | 120/157 [00:00<00:00, 205.69it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 1840/1876 [00:11<00:00, 159.34it/s, loss=0.202, v_num=10, val_loss=0.16, val_acc=0.951] \n",
      "Epoch 2:  98%|█████████▊| 1840/1876 [00:11<00:00, 159.28it/s, loss=0.202, v_num=10, val_loss=0.16, val_acc=0.951]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  89%|████████▉ | 280/313 [00:01<00:00, 202.73it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'val_acc': tensor(0.9559), 'val_loss': tensor(0.1470)}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing:  96%|█████████▌| 300/313 [00:01<00:00, 193.84it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'val_loss': 0.14701983332633972, 'val_acc': 0.9559000134468079}]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-e73c4ef4ec23a223\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-e73c4ef4ec23a223\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {}
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}