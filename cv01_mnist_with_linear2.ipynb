{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl \n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from pytorch_lightning.metrics.functional import accuracy"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(pl.LightningModule):\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conf = conf \n",
    "        channels, width, height = conf.dims\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels*width*height, conf.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(conf.hidden_size, conf.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(conf.hidden_size, conf.num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "    \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.conf.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        MNIST(self.conf.data_path, train=True, download=True)\n",
    "        MNIST(self.conf.data_path, train=False, download=True)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.conf.data_path, train=True, transform=transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.conf.data_path, train=False, transform=transform)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=32)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=32)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'data_path': 'data/',\n",
       " 'dims': (1, 28, 28),\n",
       " 'num_classes': 10,\n",
       " 'hidden_size': 64,\n",
       " 'learning_rate': 0.0002}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "conf = Config(\n",
    "    data_path=r'data/',\n",
    "    dims=(1, 28, 28),\n",
    "    num_classes=10,\n",
    "    hidden_size=64,\n",
    "    learning_rate=2e-4,\n",
    ")\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST(conf)\n",
    "trainer = pl.Trainer(max_epochs=3, progress_bar_refresh_rate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 55 K  \n",
      "Epoch 0:  91%|█████████ | 1700/1876 [00:10<00:01, 159.54it/s, loss=0.305, v_num=9]\n",
      "Epoch 0:  92%|█████████▏| 1720/1876 [00:10<00:00, 158.37it/s, loss=0.305, v_num=9]\n",
      "Epoch 0:  93%|█████████▎| 1740/1876 [00:10<00:00, 158.63it/s, loss=0.305, v_num=9]\n",
      "Epoch 0:  94%|█████████▍| 1760/1876 [00:11<00:00, 158.49it/s, loss=0.305, v_num=9]\n",
      "Epoch 0:  95%|█████████▍| 1780/1876 [00:11<00:00, 157.86it/s, loss=0.305, v_num=9]\n",
      "Epoch 0:  96%|█████████▌| 1800/1876 [00:11<00:00, 157.52it/s, loss=0.305, v_num=9]\n",
      "Epoch 0:  97%|█████████▋| 1820/1876 [00:11<00:00, 157.65it/s, loss=0.305, v_num=9]\n",
      "Epoch 0:  98%|█████████▊| 1840/1876 [00:11<00:00, 156.81it/s, loss=0.316, v_num=9, val_loss=0.253, val_acc=0.928]\n",
      "Epoch 1:  91%|█████████ | 1700/1876 [00:11<00:01, 144.16it/s, loss=0.221, v_num=9, val_loss=0.253, val_acc=0.928]\n",
      "Epoch 1:  92%|█████████▏| 1720/1876 [00:11<00:01, 143.37it/s, loss=0.221, v_num=9, val_loss=0.253, val_acc=0.928]\n",
      "Epoch 1:  94%|█████████▍| 1760/1876 [00:12<00:00, 144.35it/s, loss=0.221, v_num=9, val_loss=0.253, val_acc=0.928]\n",
      "Epoch 1:  96%|█████████▌| 1800/1876 [00:12<00:00, 145.35it/s, loss=0.221, v_num=9, val_loss=0.253, val_acc=0.928]\n",
      "Epoch 1:  98%|█████████▊| 1840/1876 [00:12<00:00, 145.33it/s, loss=0.226, v_num=9, val_loss=0.192, val_acc=0.943]\n",
      "Epoch 2:  91%|█████████ | 1700/1876 [00:10<00:01, 157.99it/s, loss=0.184, v_num=9, val_loss=0.192, val_acc=0.943]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 1720/1876 [00:11<00:00, 156.32it/s, loss=0.184, v_num=9, val_loss=0.192, val_acc=0.943]\n",
      "Validating:  25%|██▌       | 40/157 [00:00<00:00, 176.55it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 1760/1876 [00:11<00:00, 156.94it/s, loss=0.184, v_num=9, val_loss=0.192, val_acc=0.943]\n",
      "Epoch 2:  96%|█████████▌| 1800/1876 [00:11<00:00, 157.71it/s, loss=0.184, v_num=9, val_loss=0.192, val_acc=0.943]\n",
      "Epoch 2:  98%|█████████▊| 1840/1876 [00:11<00:00, 157.31it/s, loss=0.192, v_num=9, val_loss=0.155, val_acc=0.952]\n",
      "Epoch 2:  98%|█████████▊| 1840/1876 [00:11<00:00, 157.26it/s, loss=0.192, v_num=9, val_loss=0.155, val_acc=0.952]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  96%|█████████▌| 300/313 [00:01<00:00, 183.91it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'val_acc': tensor(0.9570), 'val_loss': tensor(0.1424)}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing:  96%|█████████▌| 300/313 [00:01<00:00, 178.75it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'val_loss': 0.14240151643753052, 'val_acc': 0.9570000171661377}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 55 K  \n",
      "Epoch 2:  91%|█████████ | 1700/1876 [00:11<00:01, 149.78it/s, loss=0.163, v_num=9, val_loss=0.142, val_acc=0.957]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 1720/1876 [00:11<00:01, 148.65it/s, loss=0.163, v_num=9, val_loss=0.142, val_acc=0.957]\n",
      "Epoch 2:  93%|█████████▎| 1740/1876 [00:11<00:00, 148.98it/s, loss=0.163, v_num=9, val_loss=0.142, val_acc=0.957]\n",
      "Epoch 2:  94%|█████████▍| 1760/1876 [00:11<00:00, 149.36it/s, loss=0.163, v_num=9, val_loss=0.142, val_acc=0.957]\n",
      "Epoch 2:  95%|█████████▍| 1780/1876 [00:11<00:00, 149.72it/s, loss=0.163, v_num=9, val_loss=0.142, val_acc=0.957]\n",
      "Epoch 2:  96%|█████████▌| 1800/1876 [00:12<00:00, 149.88it/s, loss=0.163, v_num=9, val_loss=0.142, val_acc=0.957]\n",
      "Epoch 2:  97%|█████████▋| 1820/1876 [00:12<00:00, 149.99it/s, loss=0.163, v_num=9, val_loss=0.142, val_acc=0.957]\n",
      "Epoch 2:  98%|█████████▊| 1840/1876 [00:12<00:00, 149.16it/s, loss=0.161, v_num=9, val_loss=0.133, val_acc=0.957]\n",
      "                                                              \u001b[A"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  96%|█████████▌| 300/313 [00:01<00:00, 183.67it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'val_acc': tensor(0.9618), 'val_loss': tensor(0.1263)}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing:  96%|█████████▌| 300/313 [00:01<00:00, 175.09it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'val_loss': 0.12629741430282593, 'val_acc': 0.9617999792098999}]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-e73c4ef4ec23a223\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-e73c4ef4ec23a223\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {}
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}